@page "/groundtruth"
@using PoC1_LegacyAnalyzer_Web.Models.GroundTruth
@using PoC1_LegacyAnalyzer_Web.Models.AgentCommunication
@using PoC1_LegacyAnalyzer_Web.Services.GroundTruth
@using PoC1_LegacyAnalyzer_Web.Services
@using PoC1_LegacyAnalyzer_Web.SampleData
@using Microsoft.AspNetCore.Components.Forms
@inject IGroundTruthValidationService ValidationService
@inject IMultiFileAnalysisService AnalysisService
@inject ILogger<GroundTruthValidation> Logger

<PageTitle>Ground Truth Validation</PageTitle>

<div class="container-fluid">
    <div class="row mb-4">
        <div class="col-12 text-center">
            <h1 class="display-4 mb-2">Ground Truth Validation</h1>
            <p class="lead text-muted">Measure AI Analysis Quality with Benchmark Datasets</p>
        </div>
    </div>

    <!-- Validation Setup -->
    <div class="row mb-4">
        <div class="col-12">
            <div class="card shadow">
                <div class="card-header bg-primary text-white">
                    <h5 class="mb-0"><i class="bi bi-gear-fill"></i> Validation Setup</h5>
                </div>
                <div class="card-body">
                    <div class="row">
                        <div class="col-md-6 mb-3">
                            <label class="form-label fw-bold">Select Benchmark Dataset:</label>
                            <select class="form-select" @bind="selectedDatasetType">
                                <option value="sample">Sample Legacy C# Benchmark</option>
                                <option value="custom">Upload Custom Dataset (JSON)</option>
                            </select>
                        </div>

                        @if (selectedDatasetType == "custom")
                        {
                            <div class="col-md-6 mb-3">
                                <label class="form-label fw-bold">Upload Dataset File:</label>
                                <InputFile OnChange="HandleDatasetUpload" accept=".json" class="form-control" />
                            </div>
                        }
                    </div>

                    @if (currentDataset != null)
                    {
                        <div class="alert alert-info mt-3">
                            <h6><i class="bi bi-info-circle"></i> Dataset Loaded</h6>
                            <p class="mb-1"><strong>Name:</strong> @currentDataset.Name</p>
                            <p class="mb-1"><strong>Files:</strong> @currentDataset.Files.Count</p>
                            <p class="mb-1"><strong>Known Issues:</strong> @currentDataset.Issues.Count</p>
                            <p class="mb-0"><strong>Tags:</strong> @string.Join(", ", currentDataset.Tags)</p>
                        </div>
                    }

                    <div class="mt-3">
                        <button class="btn btn-success" @onclick="RunValidation" disabled="@(isValidating || currentDataset == null)">
                            @if (isValidating)
                            {
                                <span class="spinner-border spinner-border-sm me-2"></span>
                                <text>Running Validation...</text>
                            }
                            else
                            {
                                <i class="bi bi-play-circle-fill"></i>
                                <text> Run Validation</text>
                            }
                        </button>

                        @if (currentDataset == null)
                        {
                            <button class="btn btn-outline-primary ms-2" @onclick="LoadSampleDataset">
                                <i class="bi bi-download"></i> Load Sample Dataset
                            </button>
                        }
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Progress Indicator -->
    @if (isValidating)
    {
        <div class="row mb-4">
            <div class="col-12">
                <div class="card">
                    <div class="card-body">
                        <div class="text-center">
                            <div class="spinner-border text-primary mb-3" role="status" style="width: 3rem; height: 3rem;"></div>
                            <h5>@currentStatus</h5>
                            <p class="text-muted">This may take 1-2 minutes...</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    }

    <!-- Validation Results -->
    @if (validationResult != null)
    {
        <div class="row mb-4">
            <div class="col-12">
                <ValidationMetricsCard ValidationResult="validationResult" />
            </div>
        </div>
    }

    <!-- Instructions -->
    @if (validationResult == null && !isValidating)
    {
        <div class="row">
            <div class="col-12">
                <div class="card">
                    <div class="card-header bg-light">
                        <h5 class="mb-0"><i class="bi bi-info-circle"></i> How Ground Truth Validation Works</h5>
                    </div>
                    <div class="card-body">
                        <h6>What is Ground Truth Validation?</h6>
                        <p>
                            Ground truth validation measures the quality of AI-generated code analysis by comparing findings
                            against a benchmark dataset with <strong>known, verified issues</strong>.
                        </p>

                        <h6 class="mt-4">Key Metrics Explained:</h6>
                        <ul>
                            <li><strong>Precision:</strong> What percentage of AI findings are actually correct?
                                <em>(Precision = True Positives / (True Positives + False Positives))</em></li>
                            <li><strong>Recall:</strong> What percentage of real issues did the AI detect?
                                <em>(Recall = True Positives / (True Positives + False Negatives))</em></li>
                            <li><strong>F1 Score:</strong> Harmonic mean of precision and recall - overall quality indicator
                                <em>(F1 = 2 × (Precision × Recall) / (Precision + Recall))</em></li>
                        </ul>

                        <h6 class="mt-4">Quality Benchmarks:</h6>
                        <div class="table-responsive">
                            <table class="table table-sm table-bordered">
                                <thead>
                                    <tr>
                                        <th>F1 Score</th>
                                        <th>Quality Level</th>
                                        <th>Recommendation</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="table-success">
                                        <td>≥ 85%</td>
                                        <td><strong>Excellent</strong></td>
                                        <td>Production ready</td>
                                    </tr>
                                    <tr class="table-info">
                                        <td>75-84%</td>
                                        <td><strong>Good</strong></td>
                                        <td>Suitable for most use cases</td>
                                    </tr>
                                    <tr class="table-warning">
                                        <td>65-74%</td>
                                        <td><strong>Moderate</strong></td>
                                        <td>Needs improvement</td>
                                    </tr>
                                    <tr class="table-danger">
                                        <td>&lt; 65%</td>
                                        <td><strong>Low</strong></td>
                                        <td>Not production ready</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>

                        <h6 class="mt-4">Sample Dataset Includes:</h6>
                        <p>
                            The sample benchmark dataset contains 5 legacy C# files with <strong>11 known issues</strong> across:
                        </p>
                        <ul>
                            <li>SQL Injection vulnerabilities</li>
                            <li>Hardcoded credentials</li>
                            <li>Legacy data access patterns (DataSet, DataTable)</li>
                            <li>Global state anti-patterns (HttpContext.Current, Session)</li>
                            <li>Architectural issues (God Object, SOLID violations)</li>
                            <li>Performance problems (synchronous I/O, resource leaks)</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    }
</div>

@code {
    private string selectedDatasetType = "sample";
    private GroundTruthDataset? currentDataset;
    private GroundTruthValidationResult? validationResult;
    private bool isValidating = false;
    private string currentStatus = "";

    protected override void OnInitialized()
    {
        // Optionally load sample dataset on page load
        // LoadSampleDataset();
    }

    private void LoadSampleDataset()
    {
        try
        {
            currentDataset = LegacyCodeBenchmark.CreateSampleDataset();
            Logger.LogInformation("Loaded sample benchmark dataset: {DatasetName}", currentDataset.Name);
            StateHasChanged();
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "Failed to load sample dataset");
        }
    }

    private async Task HandleDatasetUpload(InputFileChangeEventArgs e)
    {
        try
        {
            var file = e.File;
            using var stream = file.OpenReadStream(maxAllowedSize: 5 * 1024 * 1024); // 5MB max
            using var reader = new StreamReader(stream);
            var content = await reader.ReadToEndAsync();

            currentDataset = System.Text.Json.JsonSerializer.Deserialize<GroundTruthDataset>(content);
            Logger.LogInformation("Loaded custom dataset: {DatasetName}", currentDataset?.Name ?? "Unknown");
            StateHasChanged();
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "Failed to load custom dataset");
        }
    }

    private async Task RunValidation()
    {
        if (currentDataset == null) return;

        isValidating = true;
        validationResult = null;
        currentStatus = "Analyzing benchmark files with AI agents...";
        StateHasChanged();

        try
        {
            // Step 1: Convert benchmark files to IBrowserFile format (mock implementation)
            currentStatus = $"Preparing {currentDataset.Files.Count} benchmark files for analysis...";
            StateHasChanged();

            // Note: In a real implementation, you'd need to convert BenchmarkFile to IBrowserFile
            // For now, this is a placeholder showing the validation flow
            // You would need to create a mock IBrowserFile implementation or use actual file upload

            // Step 2: Run AI analysis on benchmark files
            currentStatus = "Running multi-agent analysis (this may take 1-2 minutes)...";
            StateHasChanged();

            // TODO: Convert BenchmarkFile list to List<IBrowserFile>
            // var browserFiles = ConvertToBrowserFiles(currentDataset.Files);
            // var analysisResult = await AnalysisService.AnalyzeMultipleFilesAsync(
            //     browserFiles,
            //     "Comprehensive legacy code review",
            //     null,
            //     default);

            // For demonstration, create a mock analysis result
            var analysisResult = CreateMockAnalysisResult();

            // Step 3: Validate findings against ground truth
            currentStatus = "Comparing AI findings against ground truth...";
            StateHasChanged();

            validationResult = await ValidationService.ValidateAsync(
                analysisResult,
                currentDataset,
                new ValidationConfiguration
                {
                    MinMatchConfidence = 70.0,
                    AllowedSeverityDifference = 1,
                    AllowedLineNumberDifference = 5,
                    CountPartialMatchesAsTruePositives = true
                });

            currentStatus = "Validation complete!";
            Logger.LogInformation(
                "Validation complete. Precision: {Precision:F1}%, Recall: {Recall:F1}%, F1: {F1:F1}%",
                validationResult.OverallMetrics.Precision,
                validationResult.OverallMetrics.Recall,
                validationResult.OverallMetrics.F1Score);
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "Validation failed");
            currentStatus = $"Validation failed: {ex.Message}";
        }
        finally
        {
            isValidating = false;
            StateHasChanged();
        }
    }

    // Mock analysis result for demonstration
    // TODO: Replace with actual analysis once file conversion is implemented
    private TeamAnalysisResult CreateMockAnalysisResult()
    {
        // This is a placeholder - in production, you'd run actual AI analysis
        return new TeamAnalysisResult
        {
            ConversationId = Guid.NewGuid().ToString(),
            AgentAnalyses = new List<PoC1_LegacyAnalyzer_Web.Models.MultiAgent.SpecialistAnalysisResult>()
        };
    }
}
